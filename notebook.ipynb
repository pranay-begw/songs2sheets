{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pretty_midi\n",
    "import librosa\n",
    "\n",
    "# import transformers and matplotlib in the cell when you call them, not globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/hice1/sgoel83/scratch/Maestro/maestro-v3.0.0/maestro-v3.0.0.json'\n",
    "data_path = '/home/hice1/sgoel83/scratch/Maestro/maestro-v3.0.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(json_path):\n",
    "    with open(json_path, 'r') as file:\n",
    "        train_data = json.load(file)\n",
    "    return train_data\n",
    "\n",
    "# train_data = load_train_data(json_path)ces once pickle file is complete \n",
    "# indices_2018 = [index for index, year in train_data.items() if year == 2018]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI2018 and CQT2018 final dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDI Pickle file\n",
    "\n",
    "import pickle\n",
    "midi_final_dict = {}\n",
    "with open('/home/hice1/amardia6/scratch/midi2018.pickle', 'rb') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(f)\n",
    "            midi_final_dict = {**midi_final_dict, **data}\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "dict_keys([0, 18, 19, 21, 22, 23, 26, 35, 61, 69, 74, 75, 87, 88, 89, 97, 110, 112, 114, 187, 223, 234, 255, 257, 280, 317, 347, 377, 392, 393, 413, 414, 443, 444, 445, 446, 453, 454, 455, 456, 476, 479, 672, 678, 679, 691, 711, 717, 724, 729, 778, 782, 852, 873, 888, 920, 931, 934, 936, 939, 945, 972, 1003, 1009, 1014, 1015, 1017, 1022, 1031, 1051, 1054, 1094, 1095, 1106, 1109, 1110, 1138, 1141, 1142, 1144, 1159, 1165, 1166, 1181, 1194, 1199, 1200, 1216, 1224, 1240, 1253, 1255, 1274])\n"
     ]
    }
   ],
   "source": [
    "print(len(midi_final_dict.keys()))\n",
    "print(midi_final_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQT WAV Pickle file\n",
    "\n",
    "import pickle\n",
    "cqt_final_dict = {}\n",
    "with open('/home/hice1/sgoel83/scratch/wav_pickle/88_bins/cqt2018_88.pickle', 'rb') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            cqt_data = pickle.load(f)\n",
    "            cqt_final_dict = {**cqt_final_dict, **cqt_data}\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "dict_keys([0, 18, 19, 21, 22, 23, 26, 35, 61, 69, 74, 75, 87, 88, 89, 97, 110, 112, 114, 187, 223, 234, 255, 257, 280, 317, 347, 377, 392, 393, 413, 414, 443, 444, 445, 446, 453, 454, 455, 456, 476, 479, 672, 678, 679, 691, 711, 717, 724, 729, 778, 782, 852, 873, 888, 920, 931, 934, 936, 939, 945, 972, 1003, 1009, 1014, 1015, 1017, 1022, 1031, 1051, 1054, 1094, 1095, 1106, 1109, 1110, 1138, 1141, 1142, 1144, 1159, 1165, 1166, 1181, 1194, 1199, 1200, 1216, 1224, 1240, 1253, 1255, 1274])\n"
     ]
    }
   ],
   "source": [
    "print(len(cqt_final_dict.keys()))\n",
    "print(cqt_final_dict.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stripping MIDI to 88 keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Shape (88, 70398)\n",
      "18: Shape (88, 70375)\n",
      "19: Shape (88, 68555)\n",
      "21: Shape (88, 112083)\n",
      "22: Shape (88, 119524)\n",
      "23: Shape (88, 111878)\n",
      "26: Shape (88, 70149)\n",
      "35: Shape (88, 52089)\n",
      "61: Shape (88, 84826)\n",
      "69: Shape (88, 34968)\n",
      "74: Shape (88, 25165)\n",
      "75: Shape (88, 29749)\n",
      "87: Shape (88, 105461)\n",
      "88: Shape (88, 102212)\n",
      "89: Shape (88, 63386)\n",
      "97: Shape (88, 29407)\n",
      "110: Shape (88, 14140)\n",
      "112: Shape (88, 19476)\n",
      "114: Shape (88, 21659)\n",
      "187: Shape (88, 161182)\n",
      "223: Shape (88, 79511)\n",
      "234: Shape (88, 170061)\n",
      "255: Shape (88, 23549)\n",
      "257: Shape (88, 27070)\n",
      "280: Shape (88, 99133)\n",
      "317: Shape (88, 56993)\n",
      "347: Shape (88, 64512)\n",
      "377: Shape (88, 224451)\n",
      "392: Shape (88, 137190)\n",
      "393: Shape (88, 184680)\n",
      "413: Shape (88, 256228)\n",
      "414: Shape (88, 242350)\n",
      "443: Shape (88, 174353)\n",
      "444: Shape (88, 174903)\n",
      "445: Shape (88, 163145)\n",
      "446: Shape (88, 175912)\n",
      "453: Shape (88, 234858)\n",
      "454: Shape (88, 208137)\n",
      "455: Shape (88, 189899)\n",
      "456: Shape (88, 199127)\n",
      "476: Shape (88, 30586)\n",
      "479: Shape (88, 20640)\n",
      "672: Shape (88, 146129)\n",
      "678: Shape (88, 164111)\n",
      "679: Shape (88, 160876)\n",
      "691: Shape (88, 33037)\n",
      "711: Shape (88, 63715)\n",
      "717: Shape (88, 132491)\n",
      "724: Shape (88, 73361)\n",
      "729: Shape (88, 109166)\n",
      "778: Shape (88, 45618)\n",
      "782: Shape (88, 31322)\n",
      "852: Shape (88, 62305)\n",
      "873: Shape (88, 83463)\n",
      "888: Shape (88, 155722)\n",
      "920: Shape (88, 80998)\n",
      "931: Shape (88, 94538)\n",
      "934: Shape (88, 85571)\n",
      "936: Shape (88, 84017)\n",
      "939: Shape (88, 52864)\n",
      "945: Shape (88, 36042)\n",
      "972: Shape (88, 130789)\n",
      "1003: Shape (88, 76026)\n",
      "1009: Shape (88, 245793)\n",
      "1014: Shape (88, 117921)\n",
      "1015: Shape (88, 102381)\n",
      "1017: Shape (88, 106091)\n",
      "1022: Shape (88, 159331)\n",
      "1031: Shape (88, 125406)\n",
      "1051: Shape (88, 145139)\n",
      "1054: Shape (88, 111984)\n",
      "1094: Shape (88, 182334)\n",
      "1095: Shape (88, 190631)\n",
      "1106: Shape (88, 72780)\n",
      "1109: Shape (88, 24932)\n",
      "1110: Shape (88, 44310)\n",
      "1138: Shape (88, 152201)\n",
      "1141: Shape (88, 188779)\n",
      "1142: Shape (88, 189719)\n",
      "1144: Shape (88, 203325)\n",
      "1159: Shape (88, 97689)\n",
      "1165: Shape (88, 152819)\n",
      "1166: Shape (88, 209805)\n",
      "1181: Shape (88, 29571)\n",
      "1194: Shape (88, 135856)\n",
      "1199: Shape (88, 25650)\n",
      "1200: Shape (88, 16566)\n",
      "1216: Shape (88, 24412)\n",
      "1224: Shape (88, 70056)\n",
      "1240: Shape (88, 58224)\n",
      "1253: Shape (88, 107146)\n",
      "1255: Shape (88, 80346)\n",
      "1274: Shape (88, 106902)\n"
     ]
    }
   ],
   "source": [
    "# A0 is 21, C8 is 108\n",
    "def strip_to_88_keys_in_place(midi_final_dict):\n",
    "    for piece in midi_final_dict:\n",
    "        if midi_final_dict[piece].shape[0] == 88:\n",
    "            continue\n",
    "        else:\n",
    "            midi_final_dict[piece] = midi_final_dict[piece][21:109, :]\n",
    "\n",
    "strip_to_88_keys_in_place(midi_final_dict=midi_final_dict)\n",
    "\n",
    "for key, array in midi_final_dict.items():\n",
    "    print(f\"{key}: Shape {array.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shaping parameters\n",
    "batch_size = 32\n",
    "slices_per_batch = 8\n",
    "time_slices = 256\n",
    "values_per_slice_per_batch = 431\n",
    "frequency_bins_x = 88\n",
    "duration_x = 10\n",
    "channels_x = 1\n",
    "keys_y = 88\n",
    "\n",
    "# time per slice in seconds = 9.995 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_parameters = {\n",
    "    'batch_size': batch_size,\n",
    "    'time_slices': time_slices,\n",
    "    'frequency_bins': frequency_bins_x,\n",
    "    'duration': duration_x,\n",
    "    'channels': channels_x}\n",
    "\n",
    "y_parameters = {\n",
    "    'batch_size': batch_size,\n",
    "    'time_slices': time_slices,\n",
    "    'num_keys': keys_y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ret 6114\n",
      "max_ret 110392\n",
      "45800.76344086022\n",
      "88.0\n",
      "[(110, 6114), (1200, 7172), (112, 8432), (479, 8914), (114, 9328), (255, 10181), (1216, 10527), (1109, 10740), (74, 10839), (1199, 11047), (257, 11662), (97, 12708), (1181, 12740), (75, 12843), (476, 13183), (782, 13536), (691, 14231), (69, 15103), (945, 15560), (1110, 19083), (778, 19670), (35, 22447), (939, 22793), (317, 24551), (1240, 25119), (852, 26876), (89, 27304), (711, 27466), (347, 27795), (19, 29554), (1224, 30214), (26, 30254), (0, 30331), (18, 30351), (1106, 31389), (724, 31610), (1003, 32786), (223, 34286), (1255, 34646), (920, 34925), (873, 35988), (936, 36210), (61, 36536), (934, 36894), (931, 40758), (1159, 42115), (280, 42736), (88, 44062), (1015, 44136), (87, 45462), (1017, 45732), (1274, 46071), (1253, 46182), (729, 47059), (23, 48214), (1054, 48238), (21, 48310), (1014, 50813), (22, 51518), (1031, 54052), (972, 56333), (717, 57097), (1194, 58526), (392, 59126), (1051, 62550), (672, 62972), (1138, 65593), (1165, 65815), (888, 67104), (1022, 68619), (679, 69285), (187, 69457), (445, 70305), (678, 70683), (234, 73269), (443, 75131), (444, 75368), (446, 75791), (1094, 78569), (393, 79578), (1141, 81315), (1142, 81707), (455, 81809), (1095, 82142), (456, 85774), (1144, 87565), (454, 89654), (1166, 90381), (377, 96707), (453, 101147), (414, 104414), (1009, 105897), (413, 110392)]\n"
     ]
    }
   ],
   "source": [
    "# Audio CQT stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# x : (88, 32, 360, 5, 1)\n",
    "# y : (88, 32, 360)\n",
    "\n",
    "x = []\n",
    "xlen = []\n",
    "count = 0\n",
    "count_0 = 0\n",
    "max_ret = 0\n",
    "min_ret = float(\"inf\")\n",
    "for idx, audio in cqt_final_dict.items():\n",
    "    # print(\"Shape 0:\" , audio.shape[0])\n",
    "    # print(\"Shape 1:\" , audio.shape[1])\n",
    "    count += audio.shape[1]\n",
    "    count_0 += audio.shape[0]\n",
    "    # print(audio.shape[1]*audio.shape[0])\n",
    "    max_ret = max(max_ret, audio.shape[1])\n",
    "    min_ret = min(min_ret, audio.shape[1])\n",
    "    xlen.append((idx, audio.shape[1]))\n",
    "print(\"min_ret\", min_ret)\n",
    "print(\"max_ret\", max_ret)\n",
    "print(count/93)\n",
    "print(count_0/93)\n",
    "xlen.sort(key=lambda a: a[1])\n",
    "print(xlen)\n",
    "# xs = [x for x in range(len(xlen))]\n",
    "\n",
    "# plt.plot(xs, xlen)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ret 14140\n",
      "max_ret 256228\n",
      "106282.04301075269\n",
      "88.0\n"
     ]
    }
   ],
   "source": [
    "# MIDI stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# x : (88, 32, 360, 5, 1)\n",
    "# y : (88, 32, 360)\n",
    "\n",
    "y = []\n",
    "ylen = []\n",
    "county = 0\n",
    "county_0 = 0\n",
    "max_ret_y = 0\n",
    "min_ret_y = float(\"inf\")\n",
    "for idx, midi in midi_final_dict.items():\n",
    "    # print(\"Shape 0:\" , audio.shape[0])\n",
    "    # print(\"Shape 1:\" , audio.shape[1])\n",
    "    county += midi.shape[1]\n",
    "    county_0 += midi.shape[0]\n",
    "    # print(audio.shape[1]*audio.shape[0])\n",
    "    max_ret_y = max(max_ret_y, midi.shape[1])\n",
    "    min_ret_y = min(min_ret_y, midi.shape[1])\n",
    "    ylen.append(midi.shape[1])\n",
    "print(\"min_ret\", min_ret_y)\n",
    "print(\"max_ret\", max_ret_y)\n",
    "print(county/93)\n",
    "print(county_0/93)\n",
    "# ylen = sorted(ylen)\n",
    "# print(ylen)\n",
    "# ys = [y for y in range(len(ylen))]\n",
    "\n",
    "# plt.plot(ys, ylen)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 110392)\n",
      "(88, 110336)\n"
     ]
    }
   ],
   "source": [
    "# audio clipped duration (numbers) = 110336\n",
    "# midi clipped duration (numbers) = 256000\n",
    "# midi clipped duration (seconds) = 2558.8309266759\n",
    "# midi time in each slice (seconds) = 2558.8309266759 / 256 = 9.9954333 s = 9995.4333 ms\n",
    "# 64ms * 156 values = 9984 ms\n",
    "# We CAN clip to 9984 ms if we'd like, by removing ~11 values.\n",
    "\n",
    "# We are only clipping the end, and not adding or clipping any values in the pieces.\n",
    "\n",
    "\n",
    "longest_piece_idx = xlen[-1][0]\n",
    "print(cqt_final_dict[longest_piece_idx].shape)\n",
    "clipped_data = np.delete(cqt_final_dict[longest_piece_idx], np.s_[110336:], axis=1)\n",
    "\n",
    "cqt_final_dict[longest_piece_idx] = clipped_data\n",
    "print(cqt_final_dict[longest_piece_idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 256228)\n",
      "(88, 256000)\n"
     ]
    }
   ],
   "source": [
    "print(midi_final_dict[longest_piece_idx].shape)\n",
    "clipped_midi = np.delete(midi_final_dict[longest_piece_idx], np.s_[256000:], axis=1)\n",
    "\n",
    "midi_final_dict[longest_piece_idx] = clipped_midi\n",
    "print(midi_final_dict[longest_piece_idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must run with a kernel of 64GB\n",
    "\n",
    "max_ret = 110336\n",
    "\n",
    "audio_largest_curr_shape = (88, max_ret)\n",
    "\n",
    "for audio_idx, audio_file in cqt_final_dict.items():\n",
    "    if audio_file.shape[1] < audio_largest_curr_shape[1]:\n",
    "        pad_width = audio_largest_curr_shape[1] - audio_file.shape[1]\n",
    "        # print(pad_width)\n",
    "        cqt_final_dict[audio_idx] = np.pad(audio_file, ((0, 0), (0, pad_width)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must run with a kernel of 64GB\n",
    "\n",
    "max_ret_y = 256000\n",
    "\n",
    "midi_largest_curr_shape = (88, max_ret_y)\n",
    "\n",
    "for midi_idx, midi_file in midi_final_dict.items():\n",
    "    if midi_file.shape[1] < midi_largest_curr_shape[1]:\n",
    "        pad_width = midi_largest_curr_shape[1] - midi_file.shape[1]\n",
    "        # print(pad_width)\n",
    "        midi_final_dict[midi_idx] = np.pad(midi_file, ((0, 0), (0, pad_width)), 'constant')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n",
      "(88, 32, 8, 431)\n",
      "(32, 8, 88, 431)\n"
     ]
    }
   ],
   "source": [
    "# audio_shape = (88,32,8,431)\n",
    "audio_shape = (88, 32, 8, 431)\n",
    "\n",
    "for audio_idx, audio_file in cqt_final_dict.items():\n",
    "    if len(audio_file.shape) == 2:\n",
    "        reshaped_audio = audio_file.reshape(audio_shape)\n",
    "        print(reshaped_audio.shape)\n",
    "        reshaped_audio_2 = np.moveaxis(reshaped_audio, 0, 2)\n",
    "        print(reshaped_audio_2.shape)\n",
    "        cqt_final_dict[audio_idx] = reshaped_audio_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n",
      "(88, 32, 8, 1000)\n",
      "(32, 8, 88, 1000)\n",
      "(32, 8, 88)\n"
     ]
    }
   ],
   "source": [
    "# midi_shape = (88, 32, 8, 1000)\n",
    "midi_shape = (88, 32, 8, 1000)\n",
    "final_midi_shape = (32, 8, 88, 1000)\n",
    "\n",
    "for midi_idx, midi_file in midi_final_dict.items():\n",
    "    if len(midi_file.shape) == 2:\n",
    "        reshaped_midi = midi_file.reshape(midi_shape)\n",
    "        print(reshaped_midi.shape)\n",
    "        reshaped_midi_2 = np.moveaxis(reshaped_midi, 0, 2)\n",
    "        print(reshaped_midi_2.shape)\n",
    "        reshaped_midi_3 = reshaped_midi_2[:, :, :, 0]\n",
    "        print(reshaped_midi_3.shape)\n",
    "        midi_final_dict[midi_idx] = reshaped_midi_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "keys = list(cqt_final_dict.keys())\n",
    "random.shuffle(keys)\n",
    "\n",
    "num_keys = len(keys)\n",
    "train_size = int(0.5 * num_keys)\n",
    "valid_size = int(0.25 * num_keys)\n",
    "\n",
    "train_keys = keys[:train_size]\n",
    "valid_keys = keys[train_size:train_size + valid_size]\n",
    "test_keys = keys[train_size + valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 18:29:04.997078: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 18:29:05.020844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732750145.039880 1188109 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732750145.045546 1188109 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 18:29:05.064249: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# class RecurrentCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(RecurrentCNN, self).__init__()\n",
    "        \n",
    "#         # Convolutional Layers\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(20, 2), stride=1)\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=(4, 2))\n",
    "        \n",
    "#         # LSTM Layers\n",
    "#         self.lstm1 = nn.LSTM(input_size=32, hidden_size=500, batch_first=True, dropout=0.75)\n",
    "#         self.lstm2 = nn.LSTM(input_size=500, hidden_size=200, batch_first=True)\n",
    "\n",
    "#         # Fully Connected Layer\n",
    "#         self.fc = nn.Linear(200, 1) \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Assuming x shape: (batch_size, 32, 360, 84, 5, 1) with CQT and MIDI dimensions as 84 and 128\n",
    "#         x = x.view(-1, 1, 84, 360)\n",
    "\n",
    "#         # Apply Convolution\n",
    "#         x = self.pool1(torch.relu(self.conv1(x)))\n",
    "#         # LSTM\n",
    "#         x = x.view(x.size(0), -1, x.size(1))  \n",
    "        \n",
    "#         # LSTM forward pass\n",
    "#         x, _ = self.lstm1(x)\n",
    "#         x, _ = self.lstm2(x)\n",
    "\n",
    "#         # Fully connected layer \n",
    "#         x = self.fc(x[:, -1, :])  \n",
    "        \n",
    "#         return torch.sigmoid(x)\n",
    "        # return model\n",
    "\n",
    "final_audio_shape = (32, 8, 88, 431, 1)\n",
    "# input_shape = (final_audio_shape[1], final_audio_shape[2], final_audio_shape[3], 1)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    conv = Conv2D(filters=20, kernel_size=(20, 2), strides=(1, 1), padding=\"same\", activation=\"relu\")\n",
    "    \n",
    "    model.add(TimeDistributed(conv, input_shape=final_audio_shape[1:]))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(4, 2), strides=(2, 1))))\n",
    "    model.add(TimeDistributed(Conv2D(20, kernel_size=(20, 2), strides=(10, 1), activation='relu')))\n",
    "#     model.add(TimeDistributed(MaxPooling2D(pool_size=(4, 2), strides=(2, 1))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(500)))\n",
    "    model.add(Bidirectional(LSTM(500, input_shape=(final_audio_shape[1], 500), return_sequences=True, recurrent_dropout=0.25)))\n",
    "    model.add(Bidirectional(LSTM(200, input_shape=(final_audio_shape[1], 500), return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(88, activation = \"sigmoid\")))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pieces_audio = []\n",
    "valid_pieces_audio = []\n",
    "for idx, audio in cqt_final_dict.items():\n",
    "    if idx in train_keys:\n",
    "        train_pieces_audio.append(audio)\n",
    "    elif idx in valid_keys:\n",
    "        valid_pieces_audio.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pieces_midi = []\n",
    "valid_pieces_midi = []\n",
    "for idx, midi in midi_final_dict.items():\n",
    "    if idx in train_keys:\n",
    "        train_pieces_midi.append(midi)\n",
    "    elif idx in valid_keys:\n",
    "        valid_pieces_midi.append(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "def data_generator(audio_batches, midi_batches):\n",
    "    while True:\n",
    "        # with tensorflow.device(\"/GPU:0\"):\n",
    "        for audio, midi in zip(audio_batches, midi_batches):\n",
    "            t_audio = tensorflow.convert_to_tensor(audio)\n",
    "            t_midi = tensorflow.convert_to_tensor(midi)\n",
    "            yield t_audio, t_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check GPU utilization\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "#     for i in range(torch.cuda.device_count()):\n",
    "#         print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "# else:\n",
    "#     print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# for dev in gpus:\n",
    "#     if dev.device_type == 'GPU':\n",
    "#         device = tf.device(dev.name)\n",
    "#         print(dev.name)\n",
    "#         break\n",
    "#     else:\n",
    "#         device = tf.device('/physical_device:CPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/sgoel83/.venv/lib/python3.10/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-27 18:29:09.291098: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/hice1/sgoel83/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from randomly initialized weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/sgoel83/.venv/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">431</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">430</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,020</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25740</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,870,500</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,004,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,921,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m431\u001b[0m, \u001b[38;5;34m20\u001b[0m) │           \u001b[38;5;34m820\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m430\u001b[0m, \u001b[38;5;34m20\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m429\u001b[0m, \u001b[38;5;34m20\u001b[0m)  │        \u001b[38;5;34m16,020\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m25740\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m500\u001b[0m)         │    \u001b[38;5;34m12,870,500\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1000\u001b[0m)        │     \u001b[38;5;34m4,004,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m400\u001b[0m)         │     \u001b[38;5;34m1,921,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m88\u001b[0m)          │        \u001b[38;5;34m35,288\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,848,228</span> (71.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,848,228\u001b[0m (71.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,848,228</span> (71.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,848,228\u001b[0m (71.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - accuracy: 0.0764 - loss: 79.0411 - val_accuracy: 0.0058 - val_loss: 95.0361\n",
      "Epoch 2/20\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - accuracy: 0.0027 - loss: 78.4208 - val_accuracy: 0.0053 - val_loss: 96.2072\n",
      "Epoch 3/20\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - accuracy: 0.0033 - loss: 78.4125 - val_accuracy: 0.0071 - val_loss: 97.5718\n",
      "Epoch 4/20\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.0042 - loss: 78.4108 - val_accuracy: 0.0063 - val_loss: 98.8690\n",
      "Epoch 5/20\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - accuracy: 0.0039 - loss: 78.4098 - val_accuracy: 0.0053 - val_loss: 99.8585\n",
      "Epoch 6/20\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 3s/step - accuracy: 0.0024 - loss: 79.5490"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m steps_per_epoch \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_pieces_audio)\n\u001b[1;32m     35\u001b[0m validation_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(valid_pieces_audio)\n\u001b[0;32m---> 37\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     38\u001b[0m     x\u001b[39m=\u001b[39;49mtrain_generator,\n\u001b[1;32m     39\u001b[0m     epochs\u001b[39m=\u001b[39;49mn_epochs,\n\u001b[1;32m     40\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m     41\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_generator,\n\u001b[1;32m     42\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m     43\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m/home/hice1/sgoel83/scratch/models/original_gross0.keras\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mIterator, tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[39m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    217\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_outputs\u001b[39m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 20\n",
    "\n",
    "while True:\n",
    "    model = create_model()\n",
    "\n",
    "    # with tensorflow.device(\"/GPU:0\"):\n",
    "        # model.to(\"GPU:0\")\n",
    "        # train_pieces_audio.to(\"GPU:0\")\n",
    "        # train_pieces_midi.to(\"GPU:0\")\n",
    "        # valid_pieces_audio.to(\"GPU:0\")\n",
    "        # valid_pieces_midi.to(\"GPU:0\")\n",
    "    \n",
    "    print(\"Training from randomly initialized weights.\")\n",
    "    opt = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=(lr / n_epochs))\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # n_train_samples = 1472\n",
    "    # n_valid_samples = 736\n",
    "\n",
    "    # print(\"Number of training batches:\", n_train_samples // batch_size)\n",
    "    # print(\"Number of validation batches:\", n_valid_samples // batch_size)\n",
    "\n",
    "    # model.fit(x=train_pieces_audio,y=train_pieces_midi, batch_size=32, epochs=n_epochs, steps_per_epoch=n_train_samples // batch_size, validation_data=(valid_pieces_audio, valid_pieces_midi), validation_steps=n_valid_samples // batch_size, validation_batch_size=32, verbose=1)\n",
    "\n",
    "    train_generator = data_generator(train_pieces_audio, train_pieces_midi)\n",
    "    valid_generator = data_generator(valid_pieces_audio, valid_pieces_midi)\n",
    "\n",
    "    steps_per_epoch = len(train_pieces_audio)\n",
    "    validation_steps = len(valid_pieces_audio)\n",
    "\n",
    "    model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.save('/home/hice1/sgoel83/scratch/models/original_gross0.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
